{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Превью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы представлена таблица, содержащая категориальные и количественные признаки (часть из них бинарные). В целях подготовки признаков будет необходимо произвести отбор наиболее информативных из них (влияющих на принятие решения). Также преобразовать категориальные данные в количественные метдом прямого кодирования, избежав при этом dammy-ловушки. Масштабирование признаков будет необходимо провести для равномерности их влияния на принятие решения, т.к. ,например, есть значения уровня дохода и количества зарегистрираванных жилых помещений, которые отличаются на 5-6 порядков.В дальнейшем необходимо разделить выборки на валидационную, тестовую и тренировачную, предварительно выделив отдельно целевой признак, оценить в нем соотношение классов и принять решение о необходимости введения весового коэффицента либо применения процедур up- downsampling. Следующим шагом будет определение оптимальной модели и ее параметров. Находить ее будем на основе значения метрики f1-score. Также сравним значения метрики AUC-ROC.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть положительного класса = 0.2037\n",
      "Часть отрицательного класса = 0.7963\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "CreditScore          10000 non-null int64\n",
      "Age                  10000 non-null int64\n",
      "Tenure               10000 non-null float64\n",
      "Balance              10000 non-null float64\n",
      "NumOfProducts        10000 non-null int64\n",
      "HasCrCard            10000 non-null int64\n",
      "IsActiveMember       10000 non-null int64\n",
      "EstimatedSalary      10000 non-null float64\n",
      "Exited               10000 non-null int64\n",
      "Geography_Germany    10000 non-null uint8\n",
      "Geography_Spain      10000 non-null uint8\n",
      "Gender_Male          10000 non-null uint8\n",
      "dtypes: float64(3), int64(6), uint8(3)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "users_bh =pd.read_csv('/datasets/Churn.csv')\n",
    "users_bh.info()\n",
    "display(users_bh.head())\n",
    "users_bh = users_bh.fillna(0)\n",
    "users_bh = users_bh.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1 )\n",
    "part_1 = users_bh[users_bh['Exited']== 1]['Exited'].count()/users_bh.shape[0]\n",
    "part_0 = users_bh[users_bh['Exited']== 0]['Exited'].count()/users_bh.shape[0]\n",
    "print('Часть положительного класса =', part_1)\n",
    "print('Часть отрицательного класса =', part_0)\n",
    "users_bh_ohe = pd.get_dummies(users_bh, drop_first = True)\n",
    "users_bh_ohe.info()\n",
    "target = users_bh_ohe['Exited']\n",
    "features = users_bh_ohe.drop(['Exited'], axis=1)\n",
    "names = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features[names])\n",
    "features[names] = scaler.transform(features[names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы по пункту 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подготовке данных в датасет загружены данные из файла, а также проведен анализ отсутствующих значений и типов данных. В столбце \"Tenure\" около 10% отстутствующих значений. Спишем это на невнимательное заполнение поля о количестве недвижимости у клиента. Скорее всего если этот пункт не заполнен, то недвижимости у клиента просто нет. Так что заполним пропуски нулями. Проведя анализ, выявили 3 неинформативных поля: RowNumber, CustomerId, Surname. Они применяются скорее для индексации данных и самой простой привязки к клиенту, но не влияют на уход клиента из банка. Просто удалим эти столбцы. В оставшихся данных есть 2 столбца с категориальным типом данных. Применим для них отображение. В результате определения распределения классов удалось выяснить, что зачений положительного класса примерно в 5 раз меньше, чем отрицательного. Придется применять весовые коэффиценты, а если не поможет, то и upsampling. Также применили масштабирование для количественных параметров (за исключением параметров с бинарными значениями).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression f1_score valid = 0.33389544688026984\n",
      "LogisticRegression f1_score test = 0.2743055555555555\n",
      "LogisticRegression auc_roc valid= 0.7586378456196807\n",
      "LogisticRegression auc_roc test= 0.7386500087696812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score = 0.5907046476761619\n",
      "best_depth = 12\n",
      "best_score_1 = 0.592814371257485\n",
      "best_estimators = 40\n",
      "RandomForestClassifier_best f1_score valid = 0.592814371257485\n",
      "RandomForestClassifier_best f1_score test = 0.5238828967642527\n",
      "RandomForestClassifier auc_roc valid= 0.843305215976385\n",
      "RandomForestClassifier auc_roc test= 0.8544112995468248\n"
     ]
    }
   ],
   "source": [
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(features, target,\n",
    "                                                                                        test_size = 0.4, random_state = 12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_test,target_valid_test,\n",
    "                                                                            test_size = 0.5, random_state = 12345)\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test = model.predict(features_test)\n",
    "print('LogisticRegression f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('LogisticRegression f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('LogisticRegression auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('LogisticRegression auc_roc test=', roc_auc_score(target_test, probabilities_one_test))\n",
    "\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 21, 1):\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_depth = depth\n",
    "print('best_score =', best_score)\n",
    "print('best_depth =', best_depth)\n",
    "best_estimators = 0\n",
    "for estimators in range(5, 101, 5):    \n",
    "    model = RandomForestClassifier(n_estimators=estimators, \n",
    "                                  max_depth = best_depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_estimators = estimators\n",
    "print('best_score_1 =', best_score)\n",
    "print('best_estimators =', best_estimators)\n",
    "model = RandomForestClassifier(n_estimators= best_estimators, \n",
    "                                  max_depth = best_depth, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test =  model.predict(features_test)\n",
    "print('RandomForestClassifier_best f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('RandomForestClassifier_best f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('RandomForestClassifier auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('RandomForestClassifier auc_roc test=', roc_auc_score(target_test, probabilities_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы по пункту 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном пункте изначально разбил данные на выборки (тренировочную, валидационную и тестовую) в сооотношении 3:1:1. Обучил модели логистической регрессии и случайного леса без учета дисбаланса классов. Для модели случайного леса определил параметры, с которыми значение метрики f1_score будет максимальным. В итоге модель логистической регрессии показала очень слабый результат даже для валидационной выборки, а модель случайного леса с количеством наблюдателей 40 и глубиной дерева 12 для валидационной выборки преодолела порог f1_score (0.592814371257485), а для тестовой выборки нет (0.5238828967642527). Придется учитывать баланс классов для улучшения качества модели. Количество наблюдателей для случайного леса изменял в диапазоне от 5 до 100 с шагом 5, а глубину дерева от 1 до 20.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression f1_score valid = 0.4888888888888888\n",
      "LogisticRegression f1_score test = 0.4797238999137188\n",
      "LogisticRegression auc_roc valid= 0.7635782940859793\n",
      "LogisticRegression auc_roc test= 0.7417846076354692\n",
      "best_score = 0.6196891191709843\n",
      "best_depth = 6\n",
      "best_score = 0.6241134751773049\n",
      "best_estimators = 95\n",
      "RandomForestClassifier_best f1_score valid = 0.6241134751773049\n",
      "RandomForestClassifier_best f1_score test = 0.597585513078471\n",
      "RandomForestClassifier auc_roc valid= 0.8537494177922684\n",
      "RandomForestClassifier auc_roc test= 0.8508584543474383\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear', class_weight = 'balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test = model.predict(features_test)\n",
    "print('LogisticRegression f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('LogisticRegression f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('LogisticRegression auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('LogisticRegression auc_roc test=', roc_auc_score(target_test, probabilities_one_test))\n",
    "\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 21, 1):\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=depth, class_weight = 'balanced',  random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_depth = depth\n",
    "print('best_score =', best_score)\n",
    "print('best_depth =', best_depth)\n",
    "best_estimators = 0\n",
    "for estimators in range(5, 101, 5):    \n",
    "    model = RandomForestClassifier(n_estimators=estimators, \n",
    "                                  max_depth = best_depth,  class_weight = 'balanced' ,random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_estimators = estimators\n",
    "print('best_score =', best_score)\n",
    "print('best_estimators =', best_estimators)\n",
    "model = RandomForestClassifier(n_estimators= best_estimators, \n",
    "                                  max_depth = best_depth, class_weight = 'balanced', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test =  model.predict(features_test)\n",
    "print('RandomForestClassifier_best f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('RandomForestClassifier_best f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('RandomForestClassifier auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('RandomForestClassifier auc_roc test=', roc_auc_score(target_test, probabilities_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "объемы тренировочных выборок до upsampling`a 6000 объектов 6000 объектов\n",
      "Часть положительного класса = 0.19933333333333333\n",
      "Часть отрицательного класса = 0.8006666666666666\n",
      "объемы тренировочных выборок после upsampling`a 7196 объектов 7196 объектов\n",
      "Часть положительного класса = 0.33240689271817675\n",
      "Часть отрицательного класса = 0.6675931072818232\n",
      "LogisticRegression f1_score valid = 0.4672435105067985\n",
      "LogisticRegression f1_score test = 0.4395061728395062\n",
      "LogisticRegression auc_roc valid= 0.7612207308294873\n",
      "LogisticRegression auc_roc test= 0.7403214950132743\n",
      "best_score = 0.6196808510638299\n",
      "best_depth = 8\n",
      "best_score = 0.6205059920106524\n",
      "best_estimators = 55\n",
      "RandomForestClassifier_best f1_score valid = 0.6205059920106524\n",
      "RandomForestClassifier_best f1_score test = 0.5922974767596282\n",
      "RandomForestClassifier auc_roc valid= 0.8548684664194679\n",
      "RandomForestClassifier auc_roc test= 0.857445459328917\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features_train[target == 0]\n",
    "    features_ones = features_train[target == 1]\n",
    "    target_zeros = target_train[target == 0]\n",
    "    target_ones = target_train[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "print('объемы тренировочных выборок до upsampling`a', features_train.shape[0], 'объектов', target_train.shape[0], 'объектов')\n",
    "part_11 = target_train[target_train== 1].count()/target_train.shape[0]\n",
    "part_00 = target_train[target_train== 0].count()/target_train.shape[0]\n",
    "print('Часть положительного класса =', part_11)\n",
    "print('Часть отрицательного класса =', part_00)\n",
    "features_train, target_train = upsample(features_train, target_train, 2)\n",
    "print('объемы тренировочных выборок после upsampling`a', features_train.shape[0], 'объектов', target_train.shape[0], 'объектов')\n",
    "part_11 = target_train[target_train== 1].count()/target_train.shape[0]\n",
    "part_00 = target_train[target_train== 0].count()/target_train.shape[0]\n",
    "print('Часть положительного класса =', part_11)\n",
    "print('Часть отрицательного класса =', part_00)\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test = model.predict(features_test)\n",
    "print('LogisticRegression f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('LogisticRegression f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('LogisticRegression auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('LogisticRegression auc_roc test=', roc_auc_score(target_test, probabilities_one_test))\n",
    "\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 21, 1):\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=depth,  random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_depth = depth\n",
    "print('best_score =', best_score)\n",
    "print('best_depth =', best_depth)\n",
    "best_estimators = 0\n",
    "for estimators in range(5, 101, 5):    \n",
    "    model = RandomForestClassifier(n_estimators=estimators, \n",
    "                                  max_depth = best_depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predict_valid)\n",
    "    if  score > best_score:\n",
    "        best_score = score  \n",
    "        best_estimators = estimators\n",
    "        if best_estimators == 0:\n",
    "            best_estimators = 1            \n",
    "print('best_score =', best_score)\n",
    "print('best_estimators =', best_estimators)\n",
    "model = RandomForestClassifier(n_estimators= best_estimators, \n",
    "                                  max_depth = best_depth, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predict_valid = model.predict(features_valid)\n",
    "predict_test =  model.predict(features_test)\n",
    "print('RandomForestClassifier_best f1_score valid =', f1_score(target_valid, predict_valid))\n",
    "print('RandomForestClassifier_best f1_score test =', f1_score(target_test, predict_test))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('RandomForestClassifier auc_roc valid=', roc_auc_score(target_valid, probabilities_one_valid))\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('RandomForestClassifier auc_roc test=', roc_auc_score(target_test, probabilities_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы по пункту 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При учете веса класса значения метрики f1_score увеличились. Особенно это заметно для модели логистичесткой регрессии (0.33389544688026984 и 0.48889). Однако лучше показатели у модели случайного леса при значениях параметров n_estimators = 95 и max_depth = 6 (0.6241134751773049 для валидационной выборки и 0.597585513078471 для тестовой, что больше порогового значения 0.59).\n",
    "Во второй части задания применил метод upsampling и увеличил количество значений положительного класса тренировочной выборки в 2 раза. соотношение классов в было ~1/4, а стало ~1/2. Итогом стало также увеличение метрики f1_score для всех моделей, а лучшая из случайного леса снова преодолела порог качества модели при параметрах best_depth = 8 и best_estimators = 55 (0.5922974767596282), но оказалась хуже, чем для баланса классов (0.597585513078471). А вот метрика AUC-ROC у последней модели хоть не значительно, но выше, что для валидационной, что для тестовой выборки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведено в ходе двух предыдущих пунктов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод по проекту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения проекта проводилась работа с данными, направленная на предсказание ухода клиента из банка. Для этого была дана таблица с характеристиками клиентов. Предварительный анализ датасета помог определить направления для подготовки данных \n",
    "перед подачей на вход моделей предсказания. Таким образом были удалены неинформативные поля, заполнены пропуски данных, проведены процедуры прямого кодирования и масштабирования признаков. Далее проведено выделение целевого признака и деление выборок на тренировочную, тестовую и валидационную. В целях тестирования выбраны модели логистической регрессии и случайного леса для задачи классификации. В ходе проведенного обучения и тестов модель логистической регрессии показала себя заметно хуже, чем модель случайного леса, опираясь на значение метрики f1_score. Особо ощутима была разница без учета весов классов. Что касается применения методов учета и подгонки весов классов, то максимальное значение метрики f1_score получено для модели случайного леса со сбалансированными классами при параметрах n_estimators = 95 и max_depth = 6 (0.597585513078471). А вот с наилучшим значением метрики AUC-ROC (0.857445459328917) получилась модель случайного леса с балансом классов 1 к 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [X]  Весь код выполняется без ошибок\n",
    "- [X]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [X]  Выполнен шаг 1: данные подготовлены\n",
    "- [X]  Выполнен шаг 2: задача исследована\n",
    "    - [X]  Исследован баланс классов\n",
    "    - [X]  Изучены модели без учёта дисбаланса\n",
    "    - [X]  Написаны выводы по результатам исследования\n",
    "- [X]  Выполнен шаг 3: учтён дисбаланс\n",
    "    - [X]  Применено несколько способов борьбы с дисбалансом\n",
    "    - [X]  Написаны выводы по результатам исследования\n",
    "- [X]  Выполнен шаг 4: проведено тестирование\n",
    "- [X]  Удалось достичь *F1*-меры не менее 0.59\n",
    "- [X]  Исследована метрика *AUC-ROC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
