# __Цель проекта__

#### Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

# __Ход выполнения проекта__

#### 1. Для работы представлена таблица, содержащая категориальные и количественные признаки (часть из них бинарные). В целях подготовки признаков будет необходимо произвести отбор наиболее информативных из них (влияющих на принятие решения). Также преобразовать категориальные данные в количественные метдом прямого кодирования, избежав при этом dammy-ловушки. Масштабирование признаков будет необходимо провести для равномерности их влияния на принятие решения, т.к. ,например, есть значения уровня дохода и количества зарегистрираванных жилых помещений, которые отличаются на 5-6 порядков.
#### 2. В дальнейшем необходимо разделить выборки на валидационную, тестовую и тренировачную, предварительно выделив отдельно целевой признак, оценить в нем соотношение классов и принять решение о необходимости введения весового коэффицента либо применения процедур up/downsampling. Следующим шагом будет определение оптимальной модели и ее параметров. Находить ее будем на основе значения метрики f1-score. Также сравним значения метрики AUC-ROC.

# __Выводы__

#### 1. В ходе выполнения проекта проводилась работа с данными, направленная на предсказание ухода клиента из банка. Для этого была дана таблица с характеристиками клиентов. Предварительный анализ датасета помог определить направления для подготовки данных перед подачей на вход моделей предсказания. Проведено выделение целевого признака и деление выборок на тренировочную, тестовую и валидационную. 

#### 2. В целях тестирования выбраны модели логистической регрессии и случайного леса для задачи классификации. В ходе проведенного обучения и тестов модель логистической регрессии показала себя заметно хуже, чем модель случайного леса, опираясь на значение метрики f1_score. Особо ощутима была разница без учета весов классов. Что касается применения методов учета и подгонки весов классов, то максимальное значение метрики f1_score получено для модели случайного леса со сбалансированными классами при параметрах n_estimators = 95 и max_depth = 6 (0.597585513078471). А вот с наилучшим значением метрики AUC-ROC (0.857445459328917) получилась модель случайного леса с балансом классов 1 к 2
